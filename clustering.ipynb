{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed # for parallelization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, HDBSCAN\n",
    "\n",
    "from stepmix.stepmix import StepMix\n",
    "# Documentation : https://github.com/Labo-Lacourse/stepmix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190dd79-e4b5-4684-98b0-0f6ce7797686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2004_i = pd.read_parquet(\"data/data2004_i.parquet\") # load imputed data\n",
    "\n",
    "# Dataset with numeric outcomes\n",
    "data_n = data2004_i[[\n",
    "    'clseusa_n', 'ambornin_n', 'amcit_n', 'amlived_n', 'amenglsh_n', \n",
    "     'amchrstn_n', 'amgovt_n', 'amfeel_n', 'amcitizn_n', 'amshamed_n', \n",
    "     'belikeus_n', 'ambetter_n', 'ifwrong_n', 'proudsss_n', 'proudgrp_n', \n",
    "     'proudpol_n', 'prouddem_n', 'proudeco_n', 'proudspt_n', 'proudart_n', \n",
    "     'proudhis_n', 'proudmil_n', 'proudsci_n']]\n",
    "\n",
    "# Dataset with categorical outcomes\n",
    "data_f = data2004_i[[\n",
    "     'clseusa_f', 'ambornin_f', 'amcit_f', 'amlived_f', 'amenglsh_f', \n",
    "     'amchrstn_f', 'amgovt_f', 'amfeel_f', 'amcitizn_f', 'amshamed_f', \n",
    "     'belikeus_f', 'ambetter_f', 'ifwrong_f', 'proudsss_f', 'proudgrp_f', \n",
    "     'proudpol_f', 'prouddem_f', 'proudeco_f', 'proudspt_f', 'proudart_f', \n",
    "     'proudhis_f', 'proudmil_f', 'proudsci_f']]\n",
    "\n",
    "# Dataset with controls\n",
    "controls = data2004_i[[\n",
    "    'sex', 'race_f', 'born_usa', 'party_fs', 'religstr_f', \n",
    "    'reltrad_f', 'region_f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b24ac-f239-4dea-9283-e3491ec65ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clust_range = range(1,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99796549-77a1-4c35-be97-9bbcd4a50a7d",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c84df2-d928-437c-b4f8-200cc8b0d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom score functions to avoid throwing errors when undefined\n",
    "def sil_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = silhouette_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score\n",
    "\n",
    "def ch_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = calinski_harabasz_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score\n",
    "\n",
    "def db_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = davies_bouldin_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edab50-f332-4177-bb46-b4664617d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt at inertia\n",
    "# Which returns per-variable values as is\n",
    "def compute_inertia(data, labels):\n",
    "    inertia = 0\n",
    "    for cluster in np.unique(labels):\n",
    "        cluster_points = data[labels == cluster]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        inertia += np.sum((cluster_points - cluster_centroid) ** 2)\n",
    "    return inertia\n",
    "\n",
    "def compute_inertia_2(data, labels):\n",
    "    # Compute cluster centroids\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = np.array([data[labels == label].mean(axis=0) for label in unique_labels])\n",
    "    \n",
    "    # Compute total inertia for the entire dataset\n",
    "    total_inertia = np.sum(\n",
    "        [np.sum((data[labels == label] - centroids[i]) ** 2) \n",
    "         for i, label in enumerate(unique_labels)]\n",
    "    )\n",
    "    \n",
    "    return total_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "589bc36d-225f-405f-b470-442a9a936829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1, 2], [1, 4], [1, 0],\n",
    "                 [10, 2], [10, 4], [10, 0]])\n",
    "labels = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "print(compute_inertia(data, labels))\n",
    "print(compute_inertia_2(data, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513b5bc-963b-41e5-a6bd-12f45f22c2f5",
   "metadata": {},
   "source": [
    "# Latent analysis\n",
    "## Without covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852e72e-ca78-477f-84a7-de05f2580e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do_StepMix(n, type, data):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "        model = StepMix(n_components=n, \n",
    "                        measurement=type, \n",
    "                        n_init=3)\n",
    "        model.fit(data)\n",
    "        pred_clust = model.predict(data)\n",
    "\n",
    "        return {\n",
    "            'n_components': n,\n",
    "            'aic': model.aic(data),\n",
    "            'bic': model.bic(data),\n",
    "            'silhouette': sil_score(data, pred_clust),\n",
    "            'calinski_harabasz': ch_score(data, pred_clust),\n",
    "            'davies_bouldin': db_score(data, pred_clust)\n",
    "        }\n",
    "\n",
    "data = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "\n",
    "cat_results = Parallel(n_jobs=8)(delayed(do_StepMix)(n, 'categorical', data) for n in clust_range)\n",
    "LCA_results = pd.DataFrame(cat_results)\n",
    "\n",
    "num_results = Parallel(n_jobs=8)(delayed(do_StepMix)(n, 'continuous', data_n) for n in clust_range)\n",
    "LPA_results = pd.DataFrame(num_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2fb00-c16f-4869-8334-4aaa1a193de9",
   "metadata": {},
   "source": [
    "## With covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d063ae3-82a3-4853-9d38-15418f0cfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 1000,\n",
    "}\n",
    "\n",
    "def do_StepMix_covar(n, type, data):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning\n",
    "\n",
    "        model = StepMix(n_components=n, \n",
    "                        measurement=type, \n",
    "                        n_init=3,\n",
    "                        n_steps=1,\n",
    "                        structural='covariate', \n",
    "                        structural_params=opt_params,\n",
    "                        init_params='kmeans',\n",
    "                        verbose=0, \n",
    "                        random_state=123)\n",
    "        model.fit(data, controls_dum)\n",
    "        pred_clust = model.predict(data)\n",
    "\n",
    "        return {\n",
    "            'n_components': n,\n",
    "            'aic': model.aic(data),\n",
    "            'bic': model.bic(data),\n",
    "            'silhouette': sil_score(data, pred_clust),\n",
    "            'calinski_harabasz': ch_score(data, pred_clust),\n",
    "            'davies_bouldin': db_score(data, pred_clust)\n",
    "        }\n",
    "\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "data = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "\n",
    "cat_results = Parallel(n_jobs=8)(delayed(do_StepMix_covar)(n, 'categorical', data) for n in clust_range)\n",
    "LCA_covar_results = pd.DataFrame(cat_results)\n",
    "\n",
    "num_results = Parallel(n_jobs=8)(delayed(do_StepMix_covar)(n, 'continuous', data_n) for n in clust_range)\n",
    "LPA_covar_results = pd.DataFrame(num_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d893bba-c892-432d-9cb0-85d85acd6304",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7df35-9998-4899-aefe-049e80a984b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_n\n",
    "results = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for init_method in ['k-means++', 'random']:\n",
    "    for n_init in [5, 10]:\n",
    "        for n_clusters in range(2,13):\n",
    "            kmeans = KMeans(\n",
    "                n_clusters=n_clusters, \n",
    "                init=init_method, \n",
    "                n_init=n_init, \n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            pred_clust = kmeans.fit_predict(scaled_data)\n",
    "            computed_inertia = compute_inertia_2(data, pred_clust)\n",
    "            results.append({\n",
    "                'n_clusters': n_clusters,\n",
    "                'init_method': init_method,\n",
    "                'n_init': n_init,\n",
    "                'inertia': kmeans.inertia_,\n",
    "                'computed_inertia': computed_inertia,\n",
    "                'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                'calinski_harabasz': calinski_harabasz_score(scaled_data, pred_clust),\n",
    "                'davies_bouldin': davies_bouldin_score(scaled_data, pred_clust)\n",
    "            })\n",
    "            # kneelocator here\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0] # Lower is better\n",
    "\n",
    "inertias = results.groupby('n_clusters')['inertia'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e39521-b8ad-40e1-8216-a74180cae967",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette\n",
    "best_calinski\n",
    "best_davies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30b7eb-ac7f-48ae-8238-769162acf975",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dc2fe-f4f7-4d74-bef3-b157be12d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5a07e-2a44-4e5e-826d-7a2ac4b6fe57",
   "metadata": {},
   "source": [
    "# HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6bc8-18fe-44b9-bd27-26a30c706672",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "min_cluster_sizes = range(2, 16)\n",
    "min_samples_range = range(1, 16)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for min_cluster_size in min_cluster_sizes:\n",
    "    for min_samples in min_samples_range:\n",
    "        hdb = HDBSCAN(min_cluster_size=min_cluster_size, \n",
    "                               min_samples=min_samples)\n",
    "        pred_clust = hdb.fit_predict(scaled_data)\n",
    "\n",
    "        n_clusters = len(set(pred_clust[pred_clust != -1]))\n",
    "        \n",
    "        results.append({\n",
    "                'min_cluster_size': min_cluster_size,\n",
    "                'min_samples': min_samples,\n",
    "                'n_clusters': n_clusters,\n",
    "                'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                'calinski_harabasz': ch_score(scaled_data, pred_clust),\n",
    "                'davies_bouldin': db_score(scaled_data, pred_clust)\n",
    "            })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8cabe-c274-4fa6-9fdb-e5a43c47fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_davies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3981c5-b365-467d-a4cb-5d6676194b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_inertia_2(data, pred_clust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e5f0e-a7c6-404d-abd4-bb302777397d",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518816f4-4411-4cd0-bf40-c46c3d9762f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "results = []\n",
    "affinity_methods = ['nearest_neighbors', 'rbf']  # Different affinity computations\n",
    "kernel_params = [0.1, 0.5, 1.0, 2.0]  # Different gamma values for RBF kernel\n",
    "\n",
    "# Standardize the data first\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for n_clusters in clust_range:\n",
    "    for affinity in affinity_methods:\n",
    "        for gamma in kernel_params:\n",
    "            # For nearest_neighbors affinity, create a connectivity matrix\n",
    "            if affinity == 'nearest_neighbors':\n",
    "                connectivity = kneighbors_graph(scaled_data, n_neighbors=10, mode='connectivity')\n",
    "                connectivity = connectivity.toarray()\n",
    "            else:\n",
    "                connectivity = None\n",
    "            \n",
    "            # Perform Spectral Clustering\n",
    "            spectral = SpectralClustering(\n",
    "                n_clusters=n_clusters,\n",
    "                affinity=affinity,\n",
    "                gamma=gamma,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Fit the model and predict clusters\n",
    "            pred_clust = spectral.fit_predict(scaled_data)\n",
    "            \n",
    "            # Count unique clusters\n",
    "            unique_clusters = len(np.unique(pred_clust))\n",
    "            \n",
    "            # Compute metrics (only if more than one cluster)\n",
    "            if unique_clusters > 1:\n",
    "                results.append({\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'affinity': affinity,\n",
    "                    'gamma': gamma,\n",
    "                    'n_unique_clusters': unique_clusters,\n",
    "                    'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                    'calinski_harabasz': calinski_harabasz_score(scaled_data, pred_clust),\n",
    "                    'davies_bouldin': davies_bouldin_score(scaled_data, pred_clust)\n",
    "                })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "# Find best configurations by different metrics\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f83ba3-fbb4-4c05-b22e-9bec4407eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f22813-ee80-4b86-a7f2-9df0a568a88d",
   "metadata": {},
   "source": [
    "# Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22142f6e-c3eb-4f95-acf4-ae88b297830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "model = AffinityPropagation(damping=0.7, max_iter=350, convergence_iter=25)\n",
    "model.fit(data)\n",
    "pred_clust = model.labels_\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "        'n_components': len(set(pred_clust)),\n",
    "        'silhouette': silhouette_score(data, pred_clust),\n",
    "        'calinski_harabasz': calinski_harabasz_score(data, pred_clust),\n",
    "        'davies_bouldin': davies_bouldin_score(data, pred_clust)\n",
    "})\n",
    "    \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fef52-d07d-4d37-a65f-17a5314110fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
