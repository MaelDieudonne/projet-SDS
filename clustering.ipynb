{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, HDBSCAN\n",
    "\n",
    "from stepmix.stepmix import StepMix\n",
    "# Documentation : https://github.com/Labo-Lacourse/stepmix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1190dd79-e4b5-4684-98b0-0f6ce7797686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2004_i = pd.read_parquet(\"data/data2004_i.parquet\") # load imputed data\n",
    "\n",
    "# Dataset with numeric outcomes\n",
    "data_n = data2004_i[[\n",
    "    'clseusa_n', 'ambornin_n', 'amcit_n', 'amlived_n', 'amenglsh_n', \n",
    "     'amchrstn_n', 'amgovt_n', 'amfeel_n', 'amcitizn_n', 'amshamed_n', \n",
    "     'belikeus_n', 'ambetter_n', 'ifwrong_n', 'proudsss_n', 'proudgrp_n', \n",
    "     'proudpol_n', 'prouddem_n', 'proudeco_n', 'proudspt_n', 'proudart_n', \n",
    "     'proudhis_n', 'proudmil_n', 'proudsci_n']]\n",
    "\n",
    "# Dataset with categorical outcomes\n",
    "data_f = data2004_i[[\n",
    "     'clseusa_f', 'ambornin_f', 'amcit_f', 'amlived_f', 'amenglsh_f', \n",
    "     'amchrstn_f', 'amgovt_f', 'amfeel_f', 'amcitizn_f', 'amshamed_f', \n",
    "     'belikeus_f', 'ambetter_f', 'ifwrong_f', 'proudsss_f', 'proudgrp_f', \n",
    "     'proudpol_f', 'prouddem_f', 'proudeco_f', 'proudspt_f', 'proudart_f', \n",
    "     'proudhis_f', 'proudmil_f', 'proudsci_f']]\n",
    "\n",
    "# Dataset with controls\n",
    "controls = data2004_i[[\n",
    "    'sex', 'race_f', 'born_usa', 'party_fs', 'religstr_f', \n",
    "    'reltrad_f', 'region_f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55b24ac-f239-4dea-9283-e3491ec65ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clust_range = range(1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e26157c-9e5b-4944-a901-7308ac46c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings thrown by StepMix using a deprectaed version of scikit learn\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99796549-77a1-4c35-be97-9bbcd4a50a7d",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c84df2-d928-437c-b4f8-200cc8b0d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom score functions to avoid throwing errors when undefined\n",
    "def sil_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = silhouette_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score\n",
    "\n",
    "def ch_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = calinski_harabasz_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score\n",
    "\n",
    "def db_score(data, pred_clust):\n",
    "    try:\n",
    "        sil_score = davies_bouldin_score(data, pred_clust)\n",
    "    except ValueError:\n",
    "        sil_score = np.nan\n",
    "    return sil_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88edab50-f332-4177-bb46-b4664617d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    }
   ],
   "source": [
    "# Attempt at inertia\n",
    "# Which returns per-variable values as is\n",
    "def compute_inertia(data, labels):\n",
    "    inertia = 0\n",
    "    for cluster in np.unique(labels):\n",
    "        cluster_points = data[labels == cluster]\n",
    "        cluster_centroid = np.mean(cluster_points, axis=0)\n",
    "        inertia += np.sum((cluster_points - cluster_centroid) ** 2)\n",
    "    return inertia\n",
    "\n",
    "def compute_inertia_2(data, labels):\n",
    "    # Compute cluster centroids\n",
    "    unique_labels = np.unique(labels)\n",
    "    centroids = np.array([data[labels == label].mean(axis=0) for label in unique_labels])\n",
    "    \n",
    "    # Compute total inertia for the entire dataset\n",
    "    total_inertia = np.sum(\n",
    "        [np.sum((data[labels == label] - centroids[i]) ** 2) \n",
    "         for i, label in enumerate(unique_labels)]\n",
    "    )\n",
    "    \n",
    "    return total_inertia\n",
    "\n",
    "data = np.array([[1, 2], [1, 4], [1, 0],\n",
    "                 [10, 2], [10, 4], [10, 0]])\n",
    "labels = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "total_inertia = compute_inertia(data, labels)\n",
    "print(total_inertia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2324cd7-0116-48a7-9558-f9a706616112",
   "metadata": {},
   "source": [
    "# Latent class analysis\n",
    "## Without covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5ec89-57aa-4ded-83aa-e41a709705f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "data = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "\n",
    "for n in clust_range:\n",
    "    model = StepMix(n_components=n, \n",
    "                    measurement='categorical', \n",
    "                    n_init=5)\n",
    "\n",
    "    model.fit(data)\n",
    "    pred_clust = model.predict(data)\n",
    "    \n",
    "    results.append({\n",
    "        'n_components': n,\n",
    "        'aic': model.aic(data),\n",
    "        'bic': model.bic(data),\n",
    "        'inertia': compute_inertia(data, pred_clust),\n",
    "        'silhouette': sil_score(data, pred_clust),\n",
    "        'calinski_harabasz': ch_score(data, pred_clust),\n",
    "        'davies_bouldin': db_score(data, pred_clust)\n",
    "    })\n",
    "\n",
    "StepMix_fnc_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3517ff-e370-4a26-beb9-0ce1e6d82b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepMix_fnc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ddeba-651a-4c3f-b93a-0f6d33af6aed",
   "metadata": {},
   "source": [
    "## With covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b405835-b1e1-464d-8a8a-48e6f166e93f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Does not converge above 3 classes\n",
    "# Try with other methods than newton-raphson, like gradient? But really slow, needs parallelizing.\n",
    "# Or without imputed data, which may cause colinearity issues?\n",
    "results = []\n",
    "\n",
    "data = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "opt_params = {\n",
    "    'method': 'newton-raphson',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500,\n",
    "}\n",
    "\n",
    "for n in clust_range:\n",
    "    model = StepMix(n_components=n, \n",
    "                    measurement='categorical', \n",
    "                    n_init=3,\n",
    "                    n_steps=1,\n",
    "                    structural='covariate', \n",
    "                    structural_params=opt_params,\n",
    "                    init_params='kmeans',\n",
    "                    verbose=0, \n",
    "                    random_state=123)\n",
    "    model.fit(data, controls_dum)\n",
    "    pred_clust = model.predict(data)\n",
    "    \n",
    "    results.append({\n",
    "        'n_components': n,\n",
    "        'aic': model.aic(data),\n",
    "        'bic': model.bic(data),\n",
    "        'silhouette': sil_score(data, pred_clust),\n",
    "        'calinski_harabasz': ch_score(data, pred_clust),\n",
    "        'davies_bouldin': db_score(data, pred_clust)\n",
    "    })\n",
    "\n",
    "StepMix_fwc_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d9666-ad86-4f3d-8e71-2cd474b8a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt at parallelizing, does not seem to work within notebooks\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "clust_range = range(1,6)\n",
    "\n",
    "results = []\n",
    "\n",
    "data = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 1000,\n",
    "}\n",
    "\n",
    "def run_StepMix(n):\n",
    "    model = StepMix(n_components=n, \n",
    "                    measurement='categorical', \n",
    "                    n_init=3,\n",
    "                    n_steps=1,\n",
    "                    structural='covariate', \n",
    "                    structural_params=opt_params,\n",
    "                    init_params='kmeans',\n",
    "                    verbose=0, \n",
    "                    random_state=123)\n",
    "    model.fit(data, controls_dum)\n",
    "    pred_clust = model.predict(data)\n",
    "\n",
    "    return {\n",
    "        'n_components': n,\n",
    "        'aic': model.aic(data),\n",
    "        'bic': model.bic(data),\n",
    "        'silhouette': sil_score(data, pred_clust),\n",
    "        'calinski_harabasz': ch_score(data, pred_clust),\n",
    "        'davies_bouldin': db_score(data, pred_clust)\n",
    "    }\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "    results = list(executor.map(run_StepMix, clust_range))\n",
    "\n",
    "StepMix_fwc_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b800047-f68d-4f31-8b89-45b0b26b2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepMix_fwc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2701a2d-1618-4deb-a85e-1f82a12dd2bd",
   "metadata": {},
   "source": [
    "# Latent profile analysis\n",
    "## Without covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca7c16-1f2f-45d2-b941-0df67c190692",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "data = data_n\n",
    "\n",
    "for n in clust_range:\n",
    "    model = StepMix(n_components=n, \n",
    "                    measurement='continuous', \n",
    "                    n_init=5)\n",
    "    model.fit(data)\n",
    "    pred_clust = model.predict(data)\n",
    "    \n",
    "    results.append({\n",
    "        'n_components': n,\n",
    "        'aic': model.aic(data),\n",
    "        'bic': model.bic(data),\n",
    "        'silhouette': sil_score(data, pred_clust),\n",
    "        'calinski_harabasz': ch_score(data, pred_clust),\n",
    "        'davies_bouldin': db_score(data, pred_clust)\n",
    "    })\n",
    "\n",
    "StepMix_nnc_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410caa-2f41-4a6c-8c3a-39bbbd5a181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepMix_nnc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f13e13-2525-4a8d-b572-eb5ef363e9cf",
   "metadata": {},
   "source": [
    "## With covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194959b0-bdcf-4250-a617-2cbc0dfa7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not converge either?\n",
    "results = []\n",
    "\n",
    "data = data_n\n",
    "controls_dum = pd.get_dummies(controls)\n",
    "\n",
    "opt_params = {\n",
    "    'method': 'newton-raphson',\n",
    "    'intercept': True,\n",
    "    'max_iter': 500,\n",
    "}\n",
    "\n",
    "for n in clust_range:\n",
    "    model = StepMix(n_components=n, \n",
    "                    measurement='continuous', \n",
    "                    n_init=3,\n",
    "                    n_steps=1,\n",
    "                    structural='covariate', \n",
    "                    structural_params=opt_params,\n",
    "                    init_params='kmeans',\n",
    "                    verbose=0, \n",
    "                    random_state=123)\n",
    "    model.fit(data, controls_dum)\n",
    "    pred_clust = model.predict(data)\n",
    "\n",
    "    results.append({\n",
    "        'n_components': n,\n",
    "        'aic': model.aic(data),\n",
    "        'bic': model.bic(data),\n",
    "        'silhouette': sil_score(data, pred_clust),\n",
    "        'calinski_harabasz': ch_score(data, pred_clust),\n",
    "        'davies_bouldin': db_score(data, pred_clust)\n",
    "    })\n",
    "\n",
    "StepMix_nwc_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ed015-b199-4154-b2bb-afeff35c4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepMix_nwc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d893bba-c892-432d-9cb0-85d85acd6304",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7df35-9998-4899-aefe-049e80a984b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_n\n",
    "results = []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for n_clusters in clust_range:\n",
    "    for init_method in ['k-means++', 'random']:\n",
    "        for n_init in [5, 10]:\n",
    "            kmeans = KMeans(\n",
    "                n_clusters=n_clusters, \n",
    "                init=init_method, \n",
    "                n_init=n_init, \n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            pred_clust = kmeans.fit_predict(scaled_data)\n",
    "            computed_inertia = compute_inertia(data, pred_clust)\n",
    "            results.append({\n",
    "                'n_clusters': n_clusters,\n",
    "                'init_method': init_method,\n",
    "                'n_init': n_init,\n",
    "                'inertia': kmeans.inertia_,\n",
    "                'computed_inertia': computed_inertia,\n",
    "                'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                'calinski_harabasz': calinski_harabasz_score(scaled_data, pred_clust),\n",
    "                'davies_bouldin': davies_bouldin_score(scaled_data, pred_clust)\n",
    "            })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0]  # Lower is better\n",
    "\n",
    "inertias = results.groupby('n_clusters')['inertia'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e39521-b8ad-40e1-8216-a74180cae967",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5a07e-2a44-4e5e-826d-7a2ac4b6fe57",
   "metadata": {},
   "source": [
    "# HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6bc8-18fe-44b9-bd27-26a30c706672",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "min_cluster_sizes = range(2, 16)\n",
    "min_samples_range = range(1, 16)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for min_cluster_size in min_cluster_sizes:\n",
    "    for min_samples in min_samples_range:\n",
    "        hdb = HDBSCAN(min_cluster_size=min_cluster_size, \n",
    "                               min_samples=min_samples)\n",
    "        pred_clust = hdb.fit_predict(scaled_data)\n",
    "\n",
    "        n_clusters = len(set(pred_clust[pred_clust != -1]))\n",
    "        \n",
    "        results.append({\n",
    "                'min_cluster_size': min_cluster_size,\n",
    "                'min_samples': min_samples,\n",
    "                'n_clusters': n_clusters,\n",
    "                'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                'calinski_harabasz': ch_score(scaled_data, pred_clust),\n",
    "                'davies_bouldin': db_score(scaled_data, pred_clust)\n",
    "            })\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8cabe-c274-4fa6-9fdb-e5a43c47fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3981c5-b365-467d-a4cb-5d6676194b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_inertia(data, pred_clust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e5f0e-a7c6-404d-abd4-bb302777397d",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518816f4-4411-4cd0-bf40-c46c3d9762f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "results = []\n",
    "affinity_methods = ['nearest_neighbors', 'rbf']  # Different affinity computations\n",
    "kernel_params = [0.1, 0.5, 1.0, 2.0]  # Different gamma values for RBF kernel\n",
    "\n",
    "# Standardize the data first\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "for n_clusters in clust_range:\n",
    "    for affinity in affinity_methods:\n",
    "        for gamma in kernel_params:\n",
    "            # For nearest_neighbors affinity, create a connectivity matrix\n",
    "            if affinity == 'nearest_neighbors':\n",
    "                connectivity = kneighbors_graph(scaled_data, n_neighbors=10, mode='connectivity')\n",
    "                connectivity = connectivity.toarray()\n",
    "            else:\n",
    "                connectivity = None\n",
    "            \n",
    "            # Perform Spectral Clustering\n",
    "            spectral = SpectralClustering(\n",
    "                n_clusters=n_clusters,\n",
    "                affinity=affinity,\n",
    "                gamma=gamma,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Fit the model and predict clusters\n",
    "            pred_clust = spectral.fit_predict(scaled_data)\n",
    "            \n",
    "            # Count unique clusters\n",
    "            unique_clusters = len(np.unique(pred_clust))\n",
    "            \n",
    "            # Compute metrics (only if more than one cluster)\n",
    "            if unique_clusters > 1:\n",
    "                results.append({\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'affinity': affinity,\n",
    "                    'gamma': gamma,\n",
    "                    'n_unique_clusters': unique_clusters,\n",
    "                    'silhouette': sil_score(scaled_data, pred_clust),\n",
    "                    'calinski_harabasz': calinski_harabasz_score(scaled_data, pred_clust),\n",
    "                    'davies_bouldin': davies_bouldin_score(scaled_data, pred_clust)\n",
    "                })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "# Find best configurations by different metrics\n",
    "best_silhouette = results.sort_values('silhouette', ascending=False).iloc[0]\n",
    "best_calinski = results.sort_values('calinski_harabasz', ascending=False).iloc[0]\n",
    "best_davies = results.sort_values('davies_bouldin', ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f83ba3-fbb4-4c05-b22e-9bec4407eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f22813-ee80-4b86-a7f2-9df0a568a88d",
   "metadata": {},
   "source": [
    "# Affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22142f6e-c3eb-4f95-acf4-ae88b297830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "model = AffinityPropagation(damping=0.7, max_iter=350, convergence_iter=25)\n",
    "model.fit(data)\n",
    "pred_clust = model.labels_\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "        'n_components': len(set(pred_clust)),\n",
    "        'silhouette': silhouette_score(data, pred_clust),\n",
    "        'calinski_harabasz': calinski_harabasz_score(data, pred_clust),\n",
    "        'davies_bouldin': davies_bouldin_score(data, pred_clust)\n",
    "})\n",
    "    \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fef52-d07d-4d37-a65f-17a5314110fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
