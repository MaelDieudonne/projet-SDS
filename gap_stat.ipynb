{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e23d8c8-bedb-4fc9-a360-d2cca2083701",
   "metadata": {},
   "source": [
    "Use GDI43 instead of 33 so that it is less close to Silhouette? By replacing average linkage by centroid distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed # for parallelization\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "# Evaluation\n",
    "from kneed import KneeLocator\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "# Visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190dd79-e4b5-4684-98b0-0f6ce7797686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2004_i = pd.read_parquet(\"data/data2004_i.parquet\") # load imputed data\n",
    "\n",
    "# Dataset with numeric outcomes\n",
    "data_n = data2004_i[[\n",
    "    # Q2\n",
    "    'clseusa_n', # 'clsetown_n', 'clsestat_n', 'clsenoam_n',\n",
    "    # Q3\n",
    "    'ambornin_n', 'amcit_n', 'amlived_n', 'amenglsh_n', \n",
    "    'amchrstn_n', 'amgovt_n', 'amfeel_n', # 'amancstr_n',\n",
    "    # Q4\n",
    "    'amcitizn_n', 'amshamed_n', 'belikeus_n', 'ambetter_n', 'ifwrong_n', # 'amsports_n', 'lessprd_n',\n",
    "    # Q5\n",
    "    'proudsss_n', 'proudgrp_n', 'proudpol_n', 'prouddem_n', 'proudeco_n',\n",
    "    'proudspt_n', 'proudart_n', 'proudhis_n', 'proudmil_n', 'proudsci_n']]\n",
    "\n",
    "## Scaling and normalizing\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "data_n_scaled = scaler.fit_transform(data_n)\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "data_n_norm = normalizer.fit_transform(data_n)\n",
    "\n",
    "# Dataset with categorical outcomes\n",
    "data_f = data2004_i[[\n",
    "    # Q2\n",
    "    'clseusa_f', # 'clsetown_f', 'clsestat_f', 'clsenoam_f',\n",
    "    # Q3\n",
    "    'ambornin_f', 'amcit_f', 'amlived_f', 'amenglsh_f', \n",
    "    'amchrstn_f', 'amgovt_f', 'amfeel_f', # 'amancstr_f',\n",
    "    # Q4\n",
    "    'amcitizn_f', 'amshamed_f', 'belikeus_f', 'ambetter_f', 'ifwrong_f', # 'amsports_f', 'lessprd_f',\n",
    "    # Q5\n",
    "    'proudsss_f', 'proudgrp_f', 'proudpol_f', 'prouddem_f', 'proudeco_f',\n",
    "    'proudspt_f', 'proudart_f', 'proudhis_f', 'proudmil_f', 'proudsci_f']]\n",
    "\n",
    "# Dataset with controls\n",
    "controls = data2004_i[[\n",
    "    'sex', 'race_f', 'born_usa', 'party_fs', 'religstr_f', \n",
    "    'reltrad_f', 'region_f']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b97bf-43e0-4516-b3ee-f226e4ebd772",
   "metadata": {},
   "source": [
    "## CVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058fa49-bfcc-479d-b5b1-3aa36681186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d3846-2199-4199-9f73-e5e17ce4613f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b24ac-f239-4dea-9283-e3491ec65ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_clust = 8\n",
    "max_threads = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513b5bc-963b-41e5-a6bd-12f45f22c2f5",
   "metadata": {},
   "source": [
    "# 1. Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bb4d5-4f87-4ff4-8407-450cb7e4ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_fit import do_StepMix, do_kmeans, do_AHC, do_hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63d684-cd9c-43f6-9e4d-f457752063f6",
   "metadata": {},
   "source": [
    "## Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d25ea9-9888-4204-b0aa-5fa9eb8936d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "data_f_oh = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "controls_dum = pd.get_dummies(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2c93b-6c33-4b31-855f-2b5a1d37a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msrt = ['categorical', 'continuous']\n",
    "covar = ['without', 'with']\n",
    "latent_params = list(product(msrt, covar))\n",
    "\n",
    "clust_range = range(1, max_clust+1)\n",
    "latent_grid = product(clust_range, latent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a46013-27ca-46c9-bc6a-f9b44aa2f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_StepMix)(data_f_oh if msrt == 'categorical' else data_n, n, msrt, covar)\n",
    "    for n, (msrt, covar) in tqdm(latent_grid, desc='Fitting latent models')\n",
    ")\n",
    "\n",
    "latent_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed3b2b-3d49-4ff6-91a0-b0b3f32a58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# clust_range = range(1, max_clust+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6260e-9cd5-453e-af98-3784188b2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models without covariates\n",
    "# cat_results_ncv = Parallel(n_jobs=max_threads)(delayed(do_StepMix)(data_f_oh, n, 'categorical', 'without') for n in clust_range)\n",
    "# num_results_ncv = Parallel(n_jobs=max_threads)(delayed(do_StepMix)(data_n, n, 'continuous', 'without') for n in clust_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240478fd-87d9-4636-a55f-063655597568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models with covariates\n",
    "# cat_results_cv = Parallel(n_jobs=max_threads)(delayed(do_StepMix)(data_f_oh, n, 'categorical', 'with') for n in clust_range)\n",
    "# num_results_cv = Parallel(n_jobs=max_threads)(delayed(do_StepMix)(data_n, n, 'continuous', 'with') for n in clust_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994024d-2b9a-453d-92b2-5903fe85f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "# latent_all = pd.concat([pd.DataFrame(cat_results_ncv),\n",
    "#                         pd.DataFrame(num_results_ncv),\n",
    "#                         pd.DataFrame(cat_results_cv),\n",
    "#                         pd.DataFrame(num_results_cv)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa257eee-187a-4c71-9f45-6001cce0b478",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87945e4f-7069-4a5e-8ec1-b0ef4cb07994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = ['euclidean', 'manhattan', 'chebyshev']\n",
    "link = ['mean', 'median', 'medoid']\n",
    "kmeans_params = list(product(dist, link))\n",
    "\n",
    "clust_range = range(2, max_clust+1)\n",
    "kmeans_grid = product(clust_range, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa878a3-e45f-4205-89dd-279a0c921f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_kmeans)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(kmeans_grid, desc='Fitting KMeans models')\n",
    ")\n",
    "\n",
    "kmeans_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a232344-8695-4408-8564-f72d79b7ecd2",
   "metadata": {},
   "source": [
    "## AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ab7f5-cafd-49ac-84da-e97c878c05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'hamming']\n",
    "linkages = ['single', 'average', 'complete']\n",
    "ahc_params = [*product(distances, linkages), ('euclidean', 'ward')]\n",
    "\n",
    "clust_range = range(1, max_clust+1)\n",
    "ahc_grid = product(clust_range, ahc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32474867-62d1-43fe-a818-47ef322016d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_AHC)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(ahc_grid, desc='Fitting AHC models')\n",
    ")\n",
    "\n",
    "ahc_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b26c1c-d087-4f08-84fe-c724be527d65",
   "metadata": {},
   "source": [
    "## HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0f087-2870-4ea9-9b31-c1fe9ab3288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'mahalanobis', 'hamming']\n",
    "min_cluster_sizes = range(2, 21)\n",
    "min_samples_range = range(1, 21)\n",
    "hdb_params = product(distances, min_cluster_sizes, min_samples_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d6adc-55fe-43cf-9fc0-0b6e4dc98031",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_hdbscan)(data_n, dist, min_c, min_s) \n",
    "    for dist, min_c, min_s in tqdm(hdb_params, desc='Fitting HDBSCAN models')\n",
    ")\n",
    "\n",
    "hdbscan_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd77545-5713-4fe0-970c-11c4d346a180",
   "metadata": {},
   "source": [
    "## Aggregate results and compare CVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce063cf-1433-4461-851a-646030af0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all, hdbscan_all]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25395e-ff74-45c3-9e37-555896c8ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CVI = all_models[['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']]\n",
    "\n",
    "correlations = all_CVI.corr(method='spearman')\n",
    "\n",
    "plt.figure(figsize=(5, 5)) \n",
    "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, \n",
    "            square=True, linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37942d04-b031-4ad2-a101-5ee01cdeca2c",
   "metadata": {},
   "source": [
    "# 2. Select models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8e1dc-5d1b-415a-b51f-a7b75be5ca46",
   "metadata": {},
   "source": [
    "## Gap stat for latent models, kmeans and AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a01e25-6da4-4f9a-ac5c-681fe87b4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23666dfd-c874-40ea-bae5-2d3f22099d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_strg(d):\n",
    "    return ', '.join(f\"{key} = {value}\" for key, value in d.items())\n",
    "\n",
    "# Generate reference data from a uniform distribution\n",
    "def gen_ref_data(data):\n",
    "    return np.random.uniform(low=data.min(axis=0), \n",
    "                            high=data.max(axis=0), \n",
    "                            size=data.shape)\n",
    "\n",
    "# Create empty df to store results\n",
    "def create_empty_df(indices):\n",
    "    cols = ['model', 'params', 'n_clust'] + \\\n",
    "       [f'{index}_gs' for index in indices] + \\\n",
    "       [f'{index}_s' for index in indices]\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    float_cols = [col for col in cols if col not in ['model', 'params', 'n_clust']]\n",
    "    df[float_cols] = df[float_cols].astype('float64')\n",
    "    \n",
    "    df['model'] = df['model'].astype('object')\n",
    "    df['params'] = df['params'].astype('object')\n",
    "    df['n_clust'] = df['n_clust'].astype('int64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726f137-707b-4c61-9b88-04f607d25026",
   "metadata": {},
   "source": [
    "### Step 1: compute the gap statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd706014-394e-46fb-bec1-4d42168e536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Gap Statistic\n",
    "def compute_gap_statistic(data, indices, iters, model, params):   \n",
    "\n",
    "    str_params = dict_to_strg(params)\n",
    "    gap_values = create_empty_df(indices)\n",
    "\n",
    "    # Loop over n values\n",
    "    if model == 'latent': n_min = 1\n",
    "    else: n_min = 2\n",
    "    \n",
    "    for n in range(n_min, max_clust+1):\n",
    "    \n",
    "        # Fit the model on random datasets\n",
    "        rand_scores_all = pd.DataFrame()\n",
    "        \n",
    "        for _ in range(iters):\n",
    "            rand_data = gen_ref_data(data)\n",
    "            \n",
    "            if model == 'latent':\n",
    "                rand_scores = do_StepMix(rand_data, n, **params)\n",
    "\n",
    "            elif model == 'kmeans':\n",
    "                rand_scores = do_kmeans(rand_data, n, **params)\n",
    "\n",
    "            elif model == 'AHC':\n",
    "                rand_scores = do_AHC(rand_data, n, **params)\n",
    "            \n",
    "            rand_scores = pd.DataFrame([rand_scores])\n",
    "            rand_scores_all = pd.concat([rand_scores_all, rand_scores], ignore_index=True)\n",
    "\n",
    "        # Retrive scores for the assessed model\n",
    "        mod_scores = all_models.loc[(all_models['model'] == model) & \n",
    "                                    (all_models['params'] == str_params) & \n",
    "                                    (all_models['n_clust'] == n)]\n",
    "\n",
    "        # Calculate the Gap statistic and s value for each validity index\n",
    "        for index in indices:\n",
    "            rand_ind = rand_scores_all[index]\n",
    "            mod_ind = mod_scores[index]\n",
    "\n",
    "            # Rescale the Silhouette index on [0,1] to avoid errors when it is negative\n",
    "            if index == 'silhouette':\n",
    "                rand_ind = (rand_ind + 1) / 2\n",
    "                mod_ind = (mod_ind + 1) / 2\n",
    "                \n",
    "            gap = np.log(np.mean(rand_ind)) - np.log(mod_ind)\n",
    "            s = np.std(np.log(rand_ind)) * np.sqrt(1 + (1 / iters))\n",
    "\n",
    "            # Store the results\n",
    "            ## Check if the corresponding row exists in the df\n",
    "            row_id = ((gap_values['model'] == model) & \n",
    "                      (gap_values['params'] == str_params) & \n",
    "                      (gap_values['n_clust'] == n))\n",
    "\n",
    "            if gap_values[row_id].empty:\n",
    "            ## If not, create a new one\n",
    "                new_row = {\n",
    "                    'model': model,\n",
    "                    'params': str_params,\n",
    "                    'n_clust': n,\n",
    "                    f'{index}_gs': gap.values[0],\n",
    "                    f'{index}_s': s\n",
    "                }\n",
    "                new_row = pd.DataFrame([new_row])\n",
    "                gap_values = pd.concat([gap_values, new_row], ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "            # Otherwise, update the existing row\n",
    "                gap_values.loc[row_id, f'{index}_gs'] = gap.values[0]\n",
    "                gap_values.loc[row_id, f'{index}_s'] = s\n",
    "\n",
    "    return gap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8683-ac4a-4048-a5a7-4d31e355fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters grid\n",
    "models = ['latent', 'kmeans', 'AHC']\n",
    "\n",
    "params = {\n",
    "    'latent': latent_params,\n",
    "    'kmeans': kmeans_params,\n",
    "    'AHC': ahc_params\n",
    "}\n",
    "\n",
    "param_names = {\n",
    "    'latent': ['msrt', 'covar'],\n",
    "    'kmeans': ['dist', 'link'],\n",
    "    'AHC': ['dist', 'link']\n",
    "}\n",
    "\n",
    "grid = [\n",
    "    (model, dict(zip(param_names[model], param_values)))\n",
    "    for model in models\n",
    "    for param_values in params[model]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda374a-ffa5-48e8-a4fe-5079cc94cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gap values for all models\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(compute_gap_statistic)(data_n, CVI, iters=5, model=model, params=config)\n",
    "    for model, config in tqdm(grid, desc = 'Bootstrapping CVIs')\n",
    ")\n",
    "\n",
    "gap_values = pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f0eaa-0fbf-4fe5-9459-2f6d251da20e",
   "metadata": {},
   "source": [
    "## Step 2: identify the optimal number of clusters for each model-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4c7b9-5a5d-44df-b59f-4a6fe058d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the optimal number of clusters\n",
    "def get_best_gap(model, params, index):\n",
    "    # Subset gap_values to the right model and params \n",
    "    rows_id = ((gap_values['model'] == model) & (gap_values['params'] == dict_to_strg(params)))\n",
    "    df = gap_values[rows_id].reset_index(drop=True)\n",
    "\n",
    "    # Extract gap and s values\n",
    "    gap = df[f'{index}_gs']\n",
    "    s = df[f'{index}_s']\n",
    "\n",
    "    # Select rows such that GS(k) >= GS(k+1) - s(k+1)\n",
    "    # Skipping the last row and adjusting for index-based calculations\n",
    "    n_min = df['n_clust'].min()\n",
    "    stats = []\n",
    "    \n",
    "    for i in range(0, len(df) - 1):\n",
    "        stat = gap[i] - gap[i+1] + s[i+1]\n",
    "        if stat >= 0: \n",
    "            stats.append([i+n_min, stat])\n",
    "\n",
    "    # Return optimal cluster number\n",
    "    stats = np.array(stats)\n",
    "    if stats.size == 0:\n",
    "        best_n = 'none'\n",
    "    else:\n",
    "        best_n = int(stats[np.argmin(stats[:, 1]), 0])\n",
    "\n",
    "    return best_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad9661-0ffa-4ce3-ba43-d0f5c60a73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to store results\n",
    "cols = ['model', 'params', 'n_clust'] + \\\n",
    "       [index for index in CVI] + \\\n",
    "       [f'{index}_abs' for index in CVI] + \\\n",
    "       [f'{index}_elbow' for index in CVI] + \\\n",
    "       [f'{index}_gap' for index in CVI]\n",
    "\n",
    "candidate_models = pd.DataFrame(columns=cols)\n",
    "\n",
    "candidate_models['model'] = candidate_models['model'].astype('object')\n",
    "candidate_models['params'] = candidate_models['params'].astype('object')\n",
    "\n",
    "float_cols = [col for col in cols if col not in ['model', 'params', 'n_clust'] + CVI]\n",
    "candidate_models[float_cols] = candidate_models[float_cols].astype('float64')\n",
    "\n",
    "int_cols = [col for col in cols if col in ['n_clust'] + CVI]\n",
    "candidate_models[int_cols] = candidate_models[int_cols].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95226fed-3e91-4bf2-bc52-6de7cae48c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best n\n",
    "for model, config in grid:\n",
    "    for index in CVI:\n",
    "        best_n = get_best_gap(model, config, index)\n",
    "\n",
    "        # Check if a best value has been identified\n",
    "        if best_n != 'none':\n",
    "            row_id = ((candidate_models['model'] == model) & \n",
    "                      (candidate_models['params'] == config) &\n",
    "                      (candidate_models['n_clust'] == best_n))\n",
    "            \n",
    "            # Check if the corresponding row exists in the df\n",
    "            if candidate_models[row_id].empty:\n",
    "\n",
    "                model_id = ((all_models['model'] == model) & \n",
    "                           (all_models['params'] == dict_to_strg(config)) &\n",
    "                           (all_models['n_clust'] == best_n))\n",
    "                \n",
    "                new_row = {\n",
    "                    'model': model,\n",
    "                    'params': config,\n",
    "                    'n_clust': best_n,\n",
    "                    'min_clust_size': all_models.loc[model_id, 'min_clust_size'].values[0],\n",
    "                    'max_clust_size': all_models.loc[model_id, 'max_clust_size'].values[0],\n",
    "                    'silhouette': all_models.loc[model_id, 'silhouette'].values[0],\n",
    "                    'calinski_harabasz': all_models.loc[model_id, 'calinski_harabasz'].values[0],\n",
    "                    'davies_bouldin': all_models.loc[model_id, 'davies_bouldin'].values[0],\n",
    "                    'dunn': all_models.loc[model_id, 'dunn'].values[0],\n",
    "                    f'{index}_gap': 1\n",
    "                }\n",
    "                \n",
    "                new_row = pd.DataFrame([new_row])\n",
    "                candidate_models = pd.concat([candidate_models, new_row], ignore_index=True)\n",
    "\n",
    "            # Otherwise, update the existing row\n",
    "            else:\n",
    "                candidate_models.loc[row_id, f'{index}_gap'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfd4b8-26e2-44c8-94a4-4784e487c101",
   "metadata": {},
   "source": [
    "## Step 3: identify the best model for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b56f0-371d-4c52-b91f-dc24963172c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI_results = {}\n",
    "\n",
    "for index in CVI:\n",
    "    CVI_results[index] = []\n",
    "    df = candidate_models[candidate_models[f'{index}_gap'] == 1]\n",
    "    \n",
    "    for model in models:\n",
    "        sub_df = df[df['model'] == model]\n",
    "\n",
    "        if sub_df.empty:\n",
    "            continue\n",
    "        else:\n",
    "            if index == 'davies_bouldin':\n",
    "                best_mod = sub_df.sort_values(index, ascending=True).iloc[0]\n",
    "            else:\n",
    "                best_mod = sub_df.sort_values(index, ascending=False).iloc[0]\n",
    "            CVI_results[index].append(best_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846f716-04a3-40a4-9615-407f482c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = pd.DataFrame(CVI_results['silhouette'])\n",
    "best_ch = pd.DataFrame(CVI_results['calinski_harabasz'])\n",
    "best_db = pd.DataFrame(CVI_results['davies_bouldin'])\n",
    "best_dunn = pd.DataFrame(CVI_results['dunn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cf2af-7104-42dc-b24c-f50879a8b1b2",
   "metadata": {},
   "source": [
    "# Min/max for HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c43f41-ddbb-4bd9-90af-ed1f9f7b2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = pd.concat([best_sil, hdbscan_all.sort_values('silhouette', ascending=False).iloc[0:1]], axis=0)\n",
    "best_ch = pd.concat([best_ch, hdbscan_all.sort_values('calinski_harabasz', ascending=False).iloc[0:1]], axis=0)\n",
    "best_db = pd.concat([best_db, hdbscan_all.sort_values('davies_bouldin', ascending=True).iloc[0:1]], axis=0)\n",
    "best_dunn = pd.concat([best_dunn, hdbscan_all.sort_values('dunn', ascending=False).iloc[0:1]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1c535-d42c-42c5-b221-a61950ff32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = best_sil.drop(columns=[col for col in best_sil.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_ch = best_ch.drop(columns=[col for col in best_ch.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_db = best_db.drop(columns=[col for col in best_db.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_dunn = best_dunn.drop(columns=[col for col in best_dunn.columns if col.endswith(('elbow', 'abs', 'gap'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b9007-b303-4ad8-95cc-2c61f46db868",
   "metadata": {},
   "source": [
    "## Elbow for AIC / BIC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d238da8-31c8-4254-938f-d7b6739eb653",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b1288-ce95-4bf4-9b48-2a88c41d2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_plot import plot_clusters, plot_cluster_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d6456-54d9-4779-9ee6-4be2dc5802cf",
   "metadata": {},
   "source": [
    "## Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f01f2-3d9b-4427-896c-53746e4d8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil.sort_values('silhouette', ascending=False).drop(columns=['calinski_harabasz', 'davies_bouldin', 'dunn']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d688725-adc2-456f-b100-877f59f426b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27952809-eaa2-4a20-bf09-697f6cffe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a6310-fea8-4863-ba70-1f7e9548bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot response variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e032f3-c798-4de8-b540-2754b600a1ed",
   "metadata": {},
   "source": [
    "## Calinski_harabasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b49d9-62fa-41a5-9ff9-b51b336bc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ch.sort_values('calinski_harabasz', ascending=False).drop(columns=['silhouette', 'davies_bouldin', 'dunn']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e198a76-d112-407a-a016-cee4d03f7e30",
   "metadata": {},
   "source": [
    "## Davies_bouldin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a791b-0d40-448d-9587-8b0e553c7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_db.sort_values('davies_bouldin', ascending=True).drop(columns=['silhouette', 'calinski_harabasz', 'dunn']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0681e-eaf8-4529-bf7a-3053a3e147d0",
   "metadata": {},
   "source": [
    "## Generalized Dunn 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b13ad-8a7a-4474-987f-053aa008ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dunn.sort_values('dunn', ascending=False).drop(columns=['silhouette', 'calinski_harabasz', 'davies_bouldin']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054c4c0-3c08-4ef8-9112-b795c7f3d511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
