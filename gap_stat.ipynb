{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887e505-68fb-40c0-adb5-06ef3199e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Parallelization and monitoring\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "# Fitting\n",
    "from stepmix.stepmix import StepMix\n",
    "from src.model_fit import do_StepMix, do_kmeans, do_AHC, do_hdbscan\n",
    "\n",
    "# Selection\n",
    "from kneed import KneeLocator\n",
    "from src.model_select import bootstrap_model, compute_gap_statistics, get_best_gap\n",
    "\n",
    "# Statistical tests\n",
    "from scipy.stats import chi2\n",
    "from src.hopkins import hopkins\n",
    "from stepmix.bootstrap import blrt_sweep\n",
    "\n",
    "# Visualization\n",
    "from src.model_plot import plot_clusters, plot_cluster_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1e61c-3574-4482-9529-59268b7fb8d6",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28820ec-976b-4d7b-92f4-62c50eb66c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [\n",
    "    # Q2\n",
    "    'clseusa', # 'clsetown', 'clsestat', 'clsenoam',\n",
    "    # Q3\n",
    "    'ambornin', 'amcit', 'amlived', 'amenglsh', \n",
    "    'amchrstn', 'amgovt', 'amfeel', # 'amancstr',\n",
    "    # Q4\n",
    "    'amcitizn', 'amshamed', 'belikeus', 'ambetter', 'ifwrong', # 'amsports', 'lessprd',\n",
    "    # Q5\n",
    "    'proudsss', 'proudgrp', 'proudpol', 'prouddem', 'proudeco',\n",
    "    'proudspt', 'proudart', 'proudhis', 'proudmil', 'proudsci'\n",
    "]\n",
    "\n",
    "var_list_f = [var + \"_f\" for var in var_list]\n",
    "var_list_n = [var + \"_n\" for var in var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620b3f0-5c01-435c-a081-e4d4edfb7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imputed data\n",
    "data2004_i = pd.read_parquet(\"data/data2004_i.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e767a2f-4830-453c-a044-bcd771b288ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with categorical outcomes\n",
    "data_f = data2004_i[var_list_f]\n",
    "\n",
    "## Label encoding\n",
    "data_f_lb = data_f.apply(lambda col: LabelEncoder().fit_transform(col))\n",
    "\n",
    "## One-hot encoding (for BVR calculation)\n",
    "columns = []\n",
    "for col in data_f_lb.columns:\n",
    "    for val in data_f_lb[col].unique():\n",
    "        columns.append((data_f_lb[col] == val).astype(int).rename(f'{col}_{val}'))\n",
    "data_f_oh = pd.concat(columns, axis=1)\n",
    "\n",
    "# Dataset with numeric outcomes\n",
    "data_n = data2004_i[var_list_n]\n",
    "\n",
    "## Scaling and normalizing\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "data_n_scaled = scaler.fit_transform(data_n)\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "data_n_norm = normalizer.fit_transform(data_n)\n",
    "\n",
    "# Dataset with controls\n",
    "controls = data2004_i[['sex', 'race_f', 'born_usa', 'party_fs', 'religstr_f', 'reltrad_f', 'region_f']]\n",
    "controls_dum = pd.get_dummies(controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d3846-2199-4199-9f73-e5e17ce4613f",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "For the Silhouette and Dunn indices, the Mahnattan distance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b24ac-f239-4dea-9283-e3491ec65ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CVI = ['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']\n",
    "max_clust = 33\n",
    "max_threads = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1513b5bc-963b-41e5-a6bd-12f45f22c2f5",
   "metadata": {},
   "source": [
    "# 1. Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63d684-cd9c-43f6-9e4d-f457752063f6",
   "metadata": {},
   "source": [
    "## 1.1. Latent\n",
    "\n",
    "With the [StepMix package](https://github.com/Labo-Lacourse/stepmix?tab=readme-ov-file). The methods used are **categorical** (= multinoulli) for LCA and **gaussian_tied** for LPA (= all gaussian components share the same general covariance matrix). The default parameter of gaussian_diag (where each gaussian component has its own diagonal covariance matrix) encountered severe convergence issues, with very unstable results. Models with covariates are fitted through the 1 step approach, where the EM algorithm is run on both the measurement and structural models. Overall, 5 initializations with kmeans++ and slightly relaxed convergence thresholds (abs_tol = rel_tol = 1e-7) proved enough to get consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2c93b-6c33-4b31-855f-2b5a1d37a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "msrt = ['categorical', 'gaussian_tied']\n",
    "covar = ['without', 'with']\n",
    "latent_params = list(product(msrt, covar))\n",
    "\n",
    "clust_range = range(1, max_clust+1)\n",
    "latent_grid = product(clust_range, latent_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a46013-27ca-46c9-bc6a-f9b44aa2f9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_StepMix)(\n",
    "        data_f_lb if msrt == 'categorical' else data_n,\n",
    "        controls_dum if covar == 'with' else None,\n",
    "        data_f_oh if msrt == 'categorical' else None,\n",
    "        n, \n",
    "        msrt, \n",
    "        covar)\n",
    "    for n, (msrt, covar) in tqdm(latent_grid, desc='Fitting latent models')\n",
    ")\n",
    "time2 = time.time()\n",
    "\n",
    "latent_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da36fb-e897-42cd-8976-a9bf57602589",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time to fit latent models: {time2-time1:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f7d26-3c78-4175-8ecf-bd03e57cc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCA_nocov = latent_all[latent_all['params'] == {'msrt': 'categorical', 'covar': 'without'}].reset_index(drop=True)\n",
    "LCA_covs = latent_all[latent_all['params'] == {'msrt': 'categorical', 'covar': 'with'}].reset_index(drop=True)\n",
    "improv_LCA = 100 * ((LCA_covs['LL'] / LCA_nocov['LL']) - 1)\n",
    "\n",
    "LPA_nocov = latent_all[latent_all['params'] == {'msrt': 'gaussian_tied', 'covar': 'without'}].reset_index(drop=True)\n",
    "LPA_covs = latent_all[latent_all['params'] == {'msrt': 'gaussian_tied', 'covar': 'with'}].reset_index(drop=True)\n",
    "improv_LPA = 100 * ((LPA_covs['LL'] / LPA_nocov['LL']) - 1)\n",
    "\n",
    "improv = pd.DataFrame({\n",
    "    \"n_clust\": range(1, len(improv_LCA) + 1),\n",
    "    \"LCA\": improv_LCA.round(1),\n",
    "    \"LPA\": improv_LPA.round(1)\n",
    "})\n",
    "\n",
    "print(\"Improvement of LL brought by covariates (in %):\")\n",
    "print(improv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbab4d0-8714-4006-9034-45ac75f600ff",
   "metadata": {},
   "source": [
    "The inclusion of covariates usually improves model fit, as it increases the log-likelihood (LL), meaning the LL becomes less negative (a negative change in a negative value moves it closer to 0). However, this improvement is moderate, typically in the 0â€“2% range. The gain in model fit does not seem proportional to the increase in computation time induced by covariates. Therefore, covariates will be dropped in subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa257eee-187a-4c71-9f45-6001cce0b478",
   "metadata": {},
   "source": [
    "## 1.2. k-means\n",
    "\n",
    "With a custom implementation, as scikit-learn does not allow to change the linkage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87945e4f-7069-4a5e-8ec1-b0ef4cb07994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = ['euclidean', 'manhattan', 'chebyshev']\n",
    "link = ['mean', 'median', 'medoid']\n",
    "kmeans_params = list(product(dist, link))\n",
    "\n",
    "clust_range = range(2, max_clust+1)\n",
    "kmeans_grid = product(clust_range, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa878a3-e45f-4205-89dd-279a0c921f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_kmeans)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(kmeans_grid, desc='Fitting KMeans models')\n",
    ")\n",
    "time2 = time.time()\n",
    "print(f\"Time to fit k-means models: {time2-time1:.2f} seconds\")\n",
    "\n",
    "kmeans_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a232344-8695-4408-8564-f72d79b7ecd2",
   "metadata": {},
   "source": [
    "## 1.3. AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ab7f5-cafd-49ac-84da-e97c878c05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'hamming']\n",
    "linkages = ['single', 'average', 'complete']\n",
    "ahc_params = [*product(distances, linkages), ('euclidean', 'ward')]\n",
    "\n",
    "clust_range = range(1, max_clust+1)\n",
    "ahc_grid = product(clust_range, ahc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32474867-62d1-43fe-a818-47ef322016d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_AHC)(data_n, n, dist, link) \n",
    "    for n, (dist, link) in tqdm(ahc_grid, desc='Fitting AHC models')\n",
    ")\n",
    "time2 = time.time()\n",
    "print(f\"Time to fit AHC models: {time2-time1:.2f} seconds\")\n",
    "\n",
    "ahc_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b26c1c-d087-4f08-84fe-c724be527d65",
   "metadata": {},
   "source": [
    "## 1.4. HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0f087-2870-4ea9-9b31-c1fe9ab3288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = ['manhattan', 'euclidean', 'chebyshev', 'mahalanobis', 'hamming']\n",
    "min_cluster_sizes = range(2, 21)\n",
    "min_samples_range = range(1, 21)\n",
    "hdb_params = product(distances, min_cluster_sizes, min_samples_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d6adc-55fe-43cf-9fc0-0b6e4dc98031",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(do_hdbscan)(data_n, dist, min_clust, min_smpl)\n",
    "    for dist, min_clust, min_smpl in tqdm(hdb_params, desc='Fitting HDBSCAN models')\n",
    ")\n",
    "time2 = time.time()\n",
    "print(f\"Time to fit HDBSCAN models: {time2-time1:.2f} seconds\")\n",
    "\n",
    "hdbscan_all = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd77545-5713-4fe0-970c-11c4d346a180",
   "metadata": {},
   "source": [
    "## 1.5. Aggregate results and compare CVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce063cf-1433-4461-851a-646030af0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all, hdbscan_all]).reset_index(drop=True)\n",
    "all_models.to_csv(\"output/models/all_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026f836-18b1-47e7-a2ab-f6fdd626bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CVI = all_models[['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn']]\n",
    "labels = {\n",
    "    'silhouette': 'Silhouette',\n",
    "    'calinski_harabasz': 'Calinski-Harabasz',\n",
    "    'davies_bouldin': 'Davies-Bouldin',\n",
    "    'dunn': 'Dunn 43'\n",
    "}\n",
    "\n",
    "correlations = all_CVI.corr(method='spearman')\n",
    "correlations = correlations.rename(index=labels, columns=labels)\n",
    "\n",
    "plt.figure(figsize=(5, 5)) \n",
    "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, \n",
    "            square=True, linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ec85e-9dc8-4ae9-bc59-f5013d0398de",
   "metadata": {},
   "source": [
    "The correlation between CVIs is generally low. Therefore, all will be retained for subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37942d04-b031-4ad2-a101-5ee01cdeca2c",
   "metadata": {},
   "source": [
    "# 2. Select models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8e1dc-5d1b-415a-b51f-a7b75be5ca46",
   "metadata": {},
   "source": [
    "## 2.1. Gap statistics for latent models, kmeans and AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a01e25-6da4-4f9a-ac5c-681fe87b4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = pd.concat([latent_all, kmeans_all, ahc_all]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34ae4f-5230-4dad-a5ac-7111d12944f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import results\n",
    "# all_models = pd.read_csv('output/models/all_models.csv')\n",
    "# all_models = all_models[all_models['n_clust'] <= max_clust]\n",
    "# all_models = all_models[all_models['model'] != 'HDBSCAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea213eae-d620-482e-9e5c-1434859f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert params to dictionary to avoid errors afterwards\n",
    "if isinstance(all_models['params'].iloc[0], str):\n",
    "    all_models['params'] = all_models['params'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726f137-707b-4c61-9b88-04f607d25026",
   "metadata": {},
   "source": [
    "*Step 1: compute the gap statistic for each model-config*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed8683-ac4a-4048-a5a7-4d31e355fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding categorical models with covariates\n",
    "latent_params = list([('categorical', 'without'),\n",
    "                      ('gaussian_tied', 'without')])\n",
    "\n",
    "params = {'kmeans': kmeans_params,\n",
    "          'AHC': ahc_params,\n",
    "          'latent': latent_params}\n",
    "\n",
    "param_names = {'kmeans': ['dist', 'link'],\n",
    "               'AHC': ['dist', 'link'],\n",
    "               'latent': ['msrt', 'covar']}\n",
    "\n",
    "models = ['kmeans', 'AHC', 'latent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fec7cd-3b63-4d4b-bc0d-3752debd1ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 30\n",
    "\n",
    "bootstrap_grid = [\n",
    "    (model, {key: value for key, value in zip(param_names[model], param_values)}, n_val, n_iter)\n",
    "    for model in models\n",
    "    for param_values in params[model]\n",
    "    for n_val in (range(1, max_clust+1) if model == 'latent' else range(2, max_clust+1))\n",
    "    for n_iter in range(iters)\n",
    "]\n",
    "\n",
    "time1 = time.time()\n",
    "results = Parallel(n_jobs=max_threads)(\n",
    "    delayed(bootstrap_model)(\n",
    "        data = data_f_lb if model == 'latent' and config.get('msrt') == 'categorical' else data_n,\n",
    "        controls = controls_dum if model == 'latent' and config.get('covar') == 'with' else None,\n",
    "        bvr_data = data_f_oh if model == 'latent' and config.get('msrt') == 'categorical' else None,\n",
    "        n = n,\n",
    "        model = model,\n",
    "        params = config,\n",
    "        iter_num = iter_num)\n",
    "    for model, config, n, iter_num in tqdm(bootstrap_grid, desc='Bootstrapping CVIs')\n",
    ")\n",
    "time2 = time.time()\n",
    "\n",
    "bootstrap_results = pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca090465-4ccc-47aa-843e-14c115d025e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time to compute gap statistics: {time2-time1:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8cea1-2e68-43d5-90b0-81ee18d68158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = [\n",
    "    (model, dict(zip(param_names[model], param_values)))\n",
    "    for model in models\n",
    "    for param_values in params[model]\n",
    "]\n",
    "\n",
    "gap_values = []\n",
    "\n",
    "for model, config in model_grid:\n",
    "    rows_id = ((bootstrap_results['model'] == model) & (bootstrap_results['params'] == config))    \n",
    "    bs_select_res = bootstrap_results[rows_id]\n",
    "    gap_stats = compute_gap_statistics(bs_select_res, all_models, model, config, CVI)\n",
    "    gap_values.append(gap_stats)\n",
    "\n",
    "gap_values = pd.concat(gap_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f0eaa-0fbf-4fe5-9459-2f6d251da20e",
   "metadata": {},
   "source": [
    "*Step 2: identify the optimal number of clusters for each model-config*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad9661-0ffa-4ce3-ba43-d0f5c60a73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df to store results\n",
    "cols = ['model', 'params', 'n_clust'] + \\\n",
    "       [index for index in CVI] + \\\n",
    "       [f'{index}_gap' for index in CVI]\n",
    "\n",
    "candidate_models = pd.DataFrame(columns=cols)\n",
    "candidate_models['model'] = candidate_models['model'].astype('object')\n",
    "candidate_models['params'] = candidate_models['params'].astype('object')\n",
    "\n",
    "float_cols = [col for col in cols if col not in ['model', 'params', 'n_clust'] + CVI]\n",
    "candidate_models[float_cols] = candidate_models[float_cols].astype('float64')\n",
    "int_cols = [col for col in cols if col in ['n_clust'] + CVI]\n",
    "candidate_models[int_cols] = candidate_models[int_cols].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95226fed-3e91-4bf2-bc52-6de7cae48c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best n\n",
    "for model, config in model_grid:\n",
    "    for index in CVI:\n",
    "        best_n = get_best_gap(gap_values, model, config, index)\n",
    "\n",
    "        # Check if a best value has been identified\n",
    "        if best_n != 'none':\n",
    "            row_id = ((candidate_models['model'] == model) & \n",
    "                      (candidate_models['params'] == config) &\n",
    "                      (candidate_models['n_clust'] == best_n))\n",
    "            \n",
    "            # Check if the corresponding row exists in the df\n",
    "            if candidate_models[row_id].empty:\n",
    "\n",
    "                model_id = ((all_models['model'] == model) & \n",
    "                           (all_models['params'] == config) &\n",
    "                           (all_models['n_clust'] == best_n))\n",
    "                \n",
    "                new_row = {\n",
    "                    'model': model,\n",
    "                    'params': config,\n",
    "                    'n_clust': best_n,\n",
    "                    'min_clust_size': all_models.loc[model_id, 'min_clust_size'].values[0],\n",
    "                    'max_clust_size': all_models.loc[model_id, 'max_clust_size'].values[0],\n",
    "                    'silhouette': all_models.loc[model_id, 'silhouette'].values[0],\n",
    "                    'calinski_harabasz': all_models.loc[model_id, 'calinski_harabasz'].values[0],\n",
    "                    'davies_bouldin': all_models.loc[model_id, 'davies_bouldin'].values[0],\n",
    "                    'dunn': all_models.loc[model_id, 'dunn'].values[0],\n",
    "                    f'{index}_gap': 1\n",
    "                }\n",
    "                \n",
    "                new_row = pd.DataFrame([new_row])\n",
    "                candidate_models = pd.concat([candidate_models, new_row], ignore_index=True)\n",
    "\n",
    "            # Otherwise, update the existing row\n",
    "            else:\n",
    "                candidate_models.loc[row_id, f'{index}_gap'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e41c5-b33b-4b36-8a65-f8ad24670dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_models.to_csv(\"output/models/candidate_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfd4b8-26e2-44c8-94a4-4784e487c101",
   "metadata": {},
   "source": [
    "*Step 3: identify the best model for each class*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b56f0-371d-4c52-b91f-dc24963172c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVI_results = {}\n",
    "\n",
    "for index in CVI:\n",
    "    CVI_results[index] = []\n",
    "    df = candidate_models[candidate_models[f'{index}_gap'] == 1]\n",
    "    \n",
    "    for model in models:\n",
    "        sub_df = df[df['model'] == model]\n",
    "\n",
    "        if sub_df.empty:\n",
    "            continue\n",
    "        else:\n",
    "            if index == 'davies_bouldin':\n",
    "                best_mod = sub_df.sort_values(index, ascending=True).iloc[0]\n",
    "            else:\n",
    "                best_mod = sub_df.sort_values(index, ascending=False).iloc[0]\n",
    "            CVI_results[index].append(best_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846f716-04a3-40a4-9615-407f482c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = pd.DataFrame(CVI_results['silhouette'])\n",
    "best_ch = pd.DataFrame(CVI_results['calinski_harabasz'])\n",
    "best_db = pd.DataFrame(CVI_results['davies_bouldin'])\n",
    "best_dunn = pd.DataFrame(CVI_results['dunn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cf2af-7104-42dc-b24c-f50879a8b1b2",
   "metadata": {},
   "source": [
    "## 2.2. Min/max for HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c43f41-ddbb-4bd9-90af-ed1f9f7b2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = pd.concat([best_sil, hdbscan_all.sort_values('silhouette', ascending=False).iloc[0:1]], axis=0)\n",
    "best_ch = pd.concat([best_ch, hdbscan_all.sort_values('calinski_harabasz', ascending=False).iloc[0:1]], axis=0)\n",
    "best_db = pd.concat([best_db, hdbscan_all.sort_values('davies_bouldin', ascending=True).iloc[0:1]], axis=0)\n",
    "best_dunn = pd.concat([best_dunn, hdbscan_all.sort_values('dunn', ascending=False).iloc[0:1]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1c535-d42c-42c5-b221-a61950ff32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sil = best_sil.drop(columns=[col for col in best_sil.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_ch = best_ch.drop(columns=[col for col in best_ch.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_db = best_db.drop(columns=[col for col in best_db.columns if col.endswith(('elbow', 'abs', 'gap'))])\n",
    "best_dunn = best_dunn.drop(columns=[col for col in best_dunn.columns if col.endswith(('elbow', 'abs', 'gap'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b9007-b303-4ad8-95cc-2c61f46db868",
   "metadata": {},
   "source": [
    "## 2.3. Fit criteria for latent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5ba4e-059e-44e1-881f-659da4e2b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_stats = latent_all.drop(columns=['silhouette', 'calinski_harabasz', 'davies_bouldin', 'dunn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc782982-c176-427c-8134-bccc3aac05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_params(d):\n",
    "    return f\"{d['msrt']} {d['covar']} covariates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154599e-f018-40a0-a9f7-667b94a00b9d",
   "metadata": {},
   "source": [
    "### 2.3.1. Absolute value for AIC / BIC / entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac80304-52d8-485c-bbf8-1b12bd5de32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = latent_all.sort_values('aic', ascending=True).iloc[0]\n",
    "best_bic = latent_all.sort_values('bic', ascending=True).iloc[0]\n",
    "best_entropy = latent_all.sort_values('entropy', ascending=False).iloc[0]\n",
    "\n",
    "print(f\"Model minimizing AIC is {disp_params(best_aic['params'])} and {best_aic['n_clust']} clusters.\")\n",
    "print(f\"Model minimizing BIC is {disp_params(best_bic['params'])} and {best_bic['n_clust']} clusters.\")\n",
    "print(f\"Model maximizing entropy is {disp_params(best_entropy['params'])} and {best_entropy['n_clust']} clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8123ce-e112-4572-8644-f292c3dd23ec",
   "metadata": {},
   "source": [
    "### 2.3.2. Elbow method for AIC / BIC / entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7826e6-4979-4398-b950-507da96a4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(df, val_index):\n",
    "    res = df.dropna(subset=[val_index])\n",
    "    x = res['n_clust']\n",
    "    y = res[val_index]\n",
    "\n",
    "    if val_index == 'entropy':\n",
    "        knee_locator = KneeLocator(x, y, curve='concave', direction='increasing')\n",
    "    else:\n",
    "        knee_locator = KneeLocator(x, y, curve='convex', direction='decreasing')\n",
    "    \n",
    "    return res[res[\"n_clust\"] == knee_locator.knee]\n",
    "\n",
    "def best_elbow_model(index):\n",
    "    candidate_models = pd.DataFrame()\n",
    "\n",
    "    for msrt in ['categorical', 'gaussian_tied']:\n",
    "        for covar in ['without', 'with']:\n",
    "            mask = (latent_stats['params'] == {'msrt': msrt, 'covar': covar})\n",
    "            models = latent_stats[mask]\n",
    "            elbow_res = elbow_method(models, index)\n",
    "            if elbow_res is not None:\n",
    "                candidate_models = pd.concat([candidate_models, elbow_res], ignore_index=True)\n",
    "    \n",
    "    if candidate_models.empty:\n",
    "        return None\n",
    "    return candidate_models.sort_values(index, ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b68044-0463-45ea-9b2b-95db7818828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aic = best_elbow_model('aic')\n",
    "best_bic = best_elbow_model('bic')\n",
    "best_entropy = best_elbow_model('entropy')\n",
    "\n",
    "print(f\"Best model according to the Elbow method applied to...\")\n",
    "\n",
    "if best_aic is None: print(\"- AIC is None\")\n",
    "else: print(f\"- AIC is {disp_params(best_aic['params'])} and {best_aic['n_clust']} clusters.\")\n",
    "\n",
    "if best_bic is None: print(\"- BIC is None\")\n",
    "else: print(f\"- BIC is {disp_params(best_bic['params'])} and {best_bic['n_clust']} clusters.\")\n",
    "    \n",
    "if best_entropy is None: print(\"- Entropy is None\")\n",
    "else: print(f\"- Entropy is {disp_params(best_entropy['params'])} and {best_entropy['n_clust']} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8941a9-83a0-44ea-8136-b20fc7831fe6",
   "metadata": {},
   "source": [
    "### 2.3.3. Statistical tests for log-likelihood\n",
    "*LRT - not advisable for comparing models with $k$ and $k-1$ classes as the resulting test statistics does not follow the $\\chi^2$ distribution under the null hypothesis. The implementation below compare models to the 1-class model, which is sometimes recommended, without a formal justification.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25d03b-0ccd-456b-90d1-13cdb8e19de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRT(models):\n",
    "    l2_red = (models['LL'].iloc[0] - models['LL']) / models['LL'].iloc[0]\n",
    "    lik_rat = 2 * (models['LL'] - models['LL'].iloc[0])\n",
    "    d_df = models['df'] - models['df'].iloc[0]\n",
    "    p_val = 1 - chi2.cdf(lik_rat, d_df)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'L2 reduction(%)': 100*l2_red,\n",
    "        'LR ratio': lik_rat,\n",
    "        'LR pval': p_val\n",
    "    }, index=models.index)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df4094-a8eb-4e11-badb-f537c9480355",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msrt in ['categorical', 'gaussian_tied']:\n",
    "    for covar in ['without', 'with']:\n",
    "        mask = (latent_stats['params'] == {'msrt': msrt, 'covar': covar})\n",
    "        models = latent_stats[mask]\n",
    "        lrt_results = LRT(models)\n",
    "        latent_stats.loc[mask, ['L2 reduction (%)', 'LR ratio', 'LR pval']] = lrt_results.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a874b0e-3c5a-4c1b-9c90-c2045123d991",
   "metadata": {},
   "source": [
    "*Bootstrapped $\\chi^2$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc3b56-303a-482a-9e80-17e2199ecf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_LCA = bootstrap_results[bootstrap_results['params'] == {'msrt': 'categorical', 'covar': 'without'}].reset_index(drop=True)\n",
    "\n",
    "grouped = boot_LCA.groupby('n_clust')\n",
    "\n",
    "chi2_results = []  \n",
    "\n",
    "for n_clust, group in grouped:\n",
    "    btsd_chi2 = np.mean(group['chi2'])\n",
    "    df = np.mean(group['chi2_df'])\n",
    "    btsd_chi2_pval = 1 - chi2.cdf(btsd_chi2, df)\n",
    "    chi2_results.append({\n",
    "        'params': {'msrt': 'categorical', 'covar': 'without'},\n",
    "        'n_clust': n_clust, \n",
    "        'btsd_chi2_stat': btsd_chi2, \n",
    "        'btsd_chi2_pval': btsd_chi2_pval})\n",
    "\n",
    "chi2_results = pd.DataFrame(chi2_results)\n",
    "\n",
    "latent_btsd = latent_all[latent_all['params'] == {'msrt': 'categorical', 'covar': 'without'}].reset_index(drop=True)\n",
    "latent_btsd = latent_btsd.merge(chi2_results, on=['n_clust'], how='left')\n",
    "latent_btsd = latent_btsd.drop(columns=['model', 'params_x', 'params_y', 'calinski_harabasz', 'davies_bouldin', 'dunn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911574f-ad61-457d-9a31-c36456cca912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_mods = latent_btsd[latent_btsd['btsd_chi2_pval'] > 0.05].shape[0]\n",
    "print(f\"Number of models where the local independance assumption holds is {sig_mods}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08a39a-ff58-4253-a30a-51ebc13097fe",
   "metadata": {},
   "source": [
    "*BLRT - not implemented in StepMix for models with covariates.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b6d99-76ab-4c4c-9f9d-56ef2dcae20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 50\n",
    "\n",
    "opt_params = {\n",
    "    'method': 'gradient',\n",
    "    'intercept': True,\n",
    "    'max_iter': 1000\n",
    "}\n",
    "\n",
    "time1 = time.time()\n",
    "for msrt in ['categorical', 'gaussian_tied']:\n",
    "    latent_mod = StepMix(\n",
    "        measurement = msrt,\n",
    "        n_init = 5,\n",
    "        init_params = 'kmeans',\n",
    "        abs_tol=1e-7,\n",
    "        rel_tol=1e-7,\n",
    "        structural_params = opt_params,\n",
    "        progress_bar = 0)\n",
    " \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "        blrt = blrt_sweep(\n",
    "            latent_mod,\n",
    "            data_f_lb if msrt == 'categorical' else data_n,\n",
    "            low=1,\n",
    "            high=max_clust,\n",
    "            n_repetitions=iters)\n",
    "\n",
    "        # Add a row for the saturated model\n",
    "        blrt = pd.concat([pd.DataFrame({'p': [np.nan]}), blrt]).reset_index(drop=True)\n",
    "\n",
    "    mask = (latent_stats['params'] == {'msrt': msrt, 'covar': 'without'})\n",
    "    latent_stats.loc[mask, ['BLR pval']] = blrt.values\n",
    "time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011168f3-c75f-4fef-a012-9696956fa40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time to compute BLRT: {time2-time1:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf8c79d-0b6e-48bb-ae7c-a03caae6d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCA = latent_stats[latent_stats['params'] == {'msrt': 'categorical', 'covar': 'without'}].reset_index(drop=True)\n",
    "LCA = LCA.merge(chi2_results, on=['n_clust'], how='left')\n",
    "LPA = latent_stats[latent_stats['params'] == {'msrt': 'gaussian_tied', 'covar': 'without'}].reset_index(drop=True)\n",
    "\n",
    "LCA.to_csv(\"output/models/bootstrapped_LCA.csv\", index=False)\n",
    "LPA.to_csv(\"output/models/bootstrapped_LPA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c1e07-1275-4cdd-8f01-80ba6d04c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LCA[LCA['BLR pval'] > 0.05].empty:\n",
    "    best_LCA = None\n",
    "else:\n",
    "    best_LCA = LCA[LCA['BLR pval'] > 0.05].iloc[0]['n_clust']\n",
    "\n",
    "if LPA[LPA['BLR pval'] > 0.05].empty:\n",
    "    best_LPA = None\n",
    "else:\n",
    "    best_LPA = LPA[LPA['BLR pval'] > 0.05].iloc[0]['n_clust']    \n",
    "\n",
    "print(f\"Optimal number of clusters for LCA according to BLRT is {best_LCA}.\")\n",
    "print(f\"Optimal number of clusters for LPA according to BLRT is {best_LPA}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc021e7a-fc39-4464-9deb-569221656a6b",
   "metadata": {},
   "source": [
    "*Results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175aa15-2be7-4a7e-87ce-77450d359f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCA.drop(columns=['model', 'params_x', 'params_y', 'aic', 'bic', 'entropy', 'chi2_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dd2e8-142c-40d7-b34c-46e218adc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA.drop(columns=['model', 'params', 'aic', 'bic', 'entropy', 'chi2', 'chi2_df', 'chi2_pval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d238da8-31c8-4254-938f-d7b6739eb653",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde9d88-bbcd-4bf0-b725-f51c59f3ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_best_model(df):\n",
    "    model = df.loc[0, 'model']\n",
    "    config = df.loc[0, 'params']\n",
    "    n_clust = int(df.loc[0, 'n_clust'])\n",
    "\n",
    "    if model == 'latent':\n",
    "        results = do_StepMix(data_f_lb if config['msrt'] == 'categorical' else data_n, n_clust, refit = True, **config)\n",
    "\n",
    "    elif model == 'kmeans':\n",
    "        results = do_kmeans(data_n, n_clust, refit = True, **config)\n",
    "    \n",
    "    elif model == 'AHC':\n",
    "        results = do_AHC(data_n, n_clust, refit = True, **config)\n",
    "    \n",
    "    elif model == 'HDBSCAN':\n",
    "        results = do_hdbscan(data_n, refit = True, **config)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d6456-54d9-4779-9ee6-4be2dc5802cf",
   "metadata": {},
   "source": [
    "## 3.1. Silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f01f2-3d9b-4427-896c-53746e4d8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil = best_sil.sort_values('silhouette', ascending=False).drop(columns=['calinski_harabasz', 'davies_bouldin', 'dunn']).reset_index(drop=True)\n",
    "sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e0967-d0b9-4828-b37a-4ba1f7664350",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clust_sil = refit_best_model(sil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27952809-eaa2-4a20-bf09-697f6cffe981",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\n",
    "    data_f_lb if (sil.loc[0, 'model'] == 'latent') and (sil.loc[0, 'params'].get('msrt') == 'categorical') else data_n,\n",
    "    pred_clust_sil,\n",
    "    '2D PCA Projection of the Best Partition According to the Silhouette Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd76e3-2cf8-4e10-9ed5-71c6a4870767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.unique(pred_clust_sil, return_counts=True)[1].min() > 5:\n",
    "    plot_cluster_profiles(data_n, pred_clust_sil, feature_names = var_list, sd = 1, title = 'Silhouette')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e032f3-c798-4de8-b540-2754b600a1ed",
   "metadata": {},
   "source": [
    "## 3.2. Calinski-Harabasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b49d9-62fa-41a5-9ff9-b51b336bc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = best_ch.sort_values('calinski_harabasz', ascending=False).drop(columns=['silhouette', 'davies_bouldin', 'dunn']).reset_index(drop=True)\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27502c-c1c8-4347-bf70-a6989038b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clust_ch = refit_best_model(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4d4c8-b7b8-4177-b6d1-1d6306ea8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\n",
    "    data_f_lb if (ch.loc[0, 'model'] == 'latent') and (ch.loc[0, 'params'].get('msrt') == 'categorical') else data_n, \n",
    "    pred_clust_ch,\n",
    "    '2D PCA Projection of the Best Partition According to the Calinski-Harabasz Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb110f5a-a42e-452d-b2ec-daa9b817ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.unique(pred_clust_ch, return_counts=True)[1].min() > 5:\n",
    "    plot_cluster_profiles(data_n, pred_clust_ch, feature_names = var_list, sd = 1, title = 'Calinski-Harabaz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e198a76-d112-407a-a016-cee4d03f7e30",
   "metadata": {},
   "source": [
    "## 3.3. Davies-Bouldin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a791b-0d40-448d-9587-8b0e553c7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = best_db.sort_values('davies_bouldin', ascending=True).drop(columns=['silhouette', 'calinski_harabasz', 'dunn']).reset_index(drop=True)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fcd9c-d6c4-4acf-ba73-c901d5f2c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clust_db = refit_best_model(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8375e-7246-4c8c-a76b-8c8b8268f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\n",
    "    data_f_lb if (db.loc[0, 'model'] == 'latent') and (db.loc[0, 'params'].get('msrt') == 'categorical') else data_n, \n",
    "    pred_clust_db,\n",
    "    '2D PCA Projection of the Best Partition According to the Davies-Bouldin Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5ab7f-39a0-4be7-9d04-192012a64a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.unique(pred_clust_db, return_counts=True)[1].min() > 5:\n",
    "    plot_cluster_profiles(data_n, pred_clust_db, feature_names = var_list, sd = 1, title = 'Davies-Bouldin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0681e-eaf8-4529-bf7a-3053a3e147d0",
   "metadata": {},
   "source": [
    "## 3.4. Generalized Dunn 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b13ad-8a7a-4474-987f-053aa008ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = best_dunn.sort_values('dunn', ascending=False).drop(columns=['silhouette', 'calinski_harabasz', 'davies_bouldin']).reset_index(drop=True)\n",
    "gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054c4c0-3c08-4ef8-9112-b795c7f3d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clust_gd = refit_best_model(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3765e69e-2b8a-4c67-b910-1430eea1f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\n",
    "    data_f_lb if (gd.loc[0, 'model'] == 'latent') and (gd.loc[0, 'params'].get('msrt') == 'categorical') else data_n, \n",
    "    pred_clust_gd,\n",
    "    '2D PCA Projection of the Best Partition According to the Generalized Dunn Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4f05e-90c7-4754-99c1-04b014d68891",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.unique(pred_clust_gd, return_counts=True)[1].min() > 5:\n",
    "    plot_cluster_profiles(data_n, pred_clust_gd, feature_names = var_list, sd = 1, title = 'Generalized Dunn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a66edd-aaaa-41e3-8a52-a40fa8b90a2a",
   "metadata": {},
   "source": [
    "# 4. Clusterability - Hopkins Statistic\n",
    "\n",
    "Function from the pyclustertend package, which could not be installed because its depencies are outdated.\n",
    "See: https://pyclustertend.readthedocs.io/en/latest/_modules/pyclustertend/hopkins.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec0caa-efaa-4671-8c21-6324d00e6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins_stat = hopkins(data_n.values, data_n.shape[0])\n",
    "print(f\"Hopkins stat on restricted data set: {hopkins_stat:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fedcb-f35c-45db-91bf-87bf7efbb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_var_list = var_list + ['clsetown', 'clsestat', 'clsenoam', 'amancstr', 'amsports', 'lessprd']\n",
    "full_var_list_n = [var + \"_n\" for var in full_var_list]\n",
    "data_n_full = data2004_i[full_var_list_n]\n",
    "hopkins_stat = hopkins(data_n_full.values, data_n.shape[0])\n",
    "print(f\"Hopkins stat on full data set: {hopkins_stat:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0aee49-8e3d-43db-ab1e-dbc62753691f",
   "metadata": {},
   "source": [
    "The inclusion of questions discared by the authors slighly improves clusterability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94471667-c481-4865-ac88-1d1b3d84f30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
